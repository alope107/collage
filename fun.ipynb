{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collage.model import Codon_Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%onnx::Add_0 : Float(1, 10, strides=[10, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Add_1 : Float(1, 10, strides=[10, 1], requires_grad=0, device=cpu),\n",
      "      %fc.weight : Float(10, 10, strides=[10, 1], requires_grad=1, device=cpu),\n",
      "      %fc.bias : Float(10, strides=[1], requires_grad=1, device=cpu)):\n",
      "  %/Add_output_0 : Float(1, 10, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/Add\"](%onnx::Add_0, %onnx::Add_1), scope: __main__.MyModel:: # /tmp/ipykernel_88295/964593827.py:10:0\n",
      "  %5 : Float(1, 10, strides=[10, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc/Gemm\"](%/Add_output_0, %fc.weight, %fc.bias), scope: __main__.MyModel::/torch.nn.modules.linear.Linear::fc # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  return (%5)\n",
      "\n",
      "============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assume your model is something like this\n",
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc = torch.nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        tgt_pad_mask = (input == 0).to( input1.device )\n",
    "        return self.fc(input1 + input2 + tgt_pad_mask)\n",
    "\n",
    "# Initialize the model\n",
    "model = MyModel()\n",
    "\n",
    "# Create dummy inputs for the forward method\n",
    "dummy_input1 = torch.randn(1, 10)\n",
    "dummy_input2 = torch.randn(1, 10)\n",
    "\n",
    "# Wrap the inputs in a tuple\n",
    "dummy_inputs = (dummy_input1, dummy_input2)\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(model, dummy_inputs, \"my_model.onnx\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Codon_Predictor( n_input_tokens = 22, \n",
    "                         n_output_tokens = 66,\n",
    "                         n_sp = 1, #len( species ),\n",
    "                         model_dim = 64, \n",
    "                         ff_dim = 256,\n",
    "                         n_heads = 4,\n",
    "                         n_encoder_layers = 1, \n",
    "                         n_decoder_layers = 2, \n",
    "                         dropout = 0.2,\n",
    "                         max_len = 500, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot = torch.tensor([[14, 13,  6,  6, 11,  1,  3, 14, 18,  1,  4, 16, 10, 11,  1,  1,  1, 15,\n",
    "         15,  6,  8,  7,  2, 15, 10, 11, 10,  3, 16,  1],\n",
    "        [ 3, 10,  7,  1,  1,  6,  6,  1,  3, 12, 13,  1,  6, 18,  3,  3,  9,  3,\n",
    "         10, 18,  9, 20,  1,  3,  8,  6,  1, 17, 20, 20],\n",
    "        [ 3,  4,  9, 17, 10, 13, 16, 10,  6,  1, 17, 10,  5, 17,  8, 10, 10, 13,\n",
    "          8,  1, 10, 11, 10, 18,  9, 17,  8,  1,  4, 10],\n",
    "        [10,  8, 17, 13, 12,  7, 18, 16,  5,  8,  3,  6,  8, 10, 10,  6, 10,  5,\n",
    "         10, 13, 18, 15, 13, 18,  5,  1, 18, 20, 17, 16]])\n",
    "cds= torch.tensor([[65, 31, 22, 56, 56, 45, 62, 55, 31, 61, 50, 59, 10,  9, 45, 62, 50, 62,\n",
    "         28, 24, 56, 33, 19,  8, 28, 13, 45, 21, 55,  6],\n",
    "        [65, 55, 29, 23, 50, 62, 52, 52, 58, 55, 39, 30, 58, 52, 49, 51, 51, 43,\n",
    "         51, 29, 49, 43,  7, 54, 51, 33, 56, 62, 34,  7],\n",
    "        [65, 51, 59, 43, 42, 25, 30, 10,  9, 56, 58, 46,  9,  5, 38, 41, 29, 25,\n",
    "         22, 33, 62, 29, 45, 13, 49, 43, 46, 33, 54, 59],\n",
    "        [65, 25, 33, 46, 18, 35, 23, 53,  2,  1, 33, 51, 56, 33, 13, 17, 60, 29,\n",
    "          1,  9, 18, 61, 20, 26, 61,  1, 54, 49,  7, 38]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROT tensor([[14, 13,  6,  6, 11,  1,  3, 14, 18,  1,  4, 16, 10, 11,  1,  1,  1, 15,\n",
      "         15,  6,  8,  7,  2, 15, 10, 11, 10,  3, 16,  1],\n",
      "        [ 3, 10,  7,  1,  1,  6,  6,  1,  3, 12, 13,  1,  6, 18,  3,  3,  9,  3,\n",
      "         10, 18,  9, 20,  1,  3,  8,  6,  1, 17, 20, 20],\n",
      "        [ 3,  4,  9, 17, 10, 13, 16, 10,  6,  1, 17, 10,  5, 17,  8, 10, 10, 13,\n",
      "          8,  1, 10, 11, 10, 18,  9, 17,  8,  1,  4, 10],\n",
      "        [10,  8, 17, 13, 12,  7, 18, 16,  5,  8,  3,  6,  8, 10, 10,  6, 10,  5,\n",
      "         10, 13, 18, 15, 13, 18,  5,  1, 18, 20, 17, 16]])\n",
      "CDS tensor([[65, 31, 22, 56, 56, 45, 62, 55, 31, 61, 50, 59, 10,  9, 45, 62, 50, 62,\n",
      "         28, 24, 56, 33, 19,  8, 28, 13, 45, 21, 55,  6],\n",
      "        [65, 55, 29, 23, 50, 62, 52, 52, 58, 55, 39, 30, 58, 52, 49, 51, 51, 43,\n",
      "         51, 29, 49, 43,  7, 54, 51, 33, 56, 62, 34,  7],\n",
      "        [65, 51, 59, 43, 42, 25, 30, 10,  9, 56, 58, 46,  9,  5, 38, 41, 29, 25,\n",
      "         22, 33, 62, 29, 45, 13, 49, 43, 46, 33, 54, 59],\n",
      "        [65, 25, 33, 46, 18, 35, 23, 53,  2,  1, 33, 51, 56, 33, 13, 17, 60, 29,\n",
      "          1,  9, 18, 61, 20, 26, 61,  1, 54, 49,  7, 38]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[   -inf,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
       "         [   -inf,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
       "         [   -inf,    -inf,    -inf,  ...,    -inf,    -inf, -2.1312],\n",
       "         ...,\n",
       "         [   -inf,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
       "         [   -inf,    -inf, -2.1545,  ...,    -inf,    -inf,    -inf],\n",
       "         [   -inf,    -inf,    -inf,  ..., -1.0194,    -inf,    -inf]],\n",
       "\n",
       "        [[   -inf,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
       "         [   -inf,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
       "         [   -inf,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
       "         ...,\n",
       "         [   -inf,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
       "         [   -inf,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
       "         [   -inf,    -inf,    -inf,  ...,    -inf,    -inf,    -inf]],\n",
       "\n",
       "        [[   -inf,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
       "         [   -inf,    -inf,    -inf,  ...,    -inf, -1.1794,    -inf],\n",
       "         [   -inf,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
       "         ...,\n",
       "         [   -inf,    -inf,    -inf,  ..., -1.1326,    -inf,    -inf],\n",
       "         [   -inf,    -inf,    -inf,  ...,    -inf, -1.1683,    -inf],\n",
       "         [   -inf,    -inf,    -inf,  ...,    -inf,    -inf,    -inf]],\n",
       "\n",
       "        [[   -inf,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
       "         [   -inf,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
       "         [   -inf,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
       "         ...,\n",
       "         [   -inf,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
       "         [   -inf,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
       "         [   -inf,    -inf, -2.0218,  ...,    -inf,    -inf,    -inf]]],\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(prot, cds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROT tensor([[14, 13,  6,  6, 11,  1,  3, 14, 18,  1,  4, 16, 10, 11,  1,  1,  1, 15,\n",
      "         15,  6,  8,  7,  2, 15, 10, 11, 10,  3, 16,  1],\n",
      "        [ 3, 10,  7,  1,  1,  6,  6,  1,  3, 12, 13,  1,  6, 18,  3,  3,  9,  3,\n",
      "         10, 18,  9, 20,  1,  3,  8,  6,  1, 17, 20, 20],\n",
      "        [ 3,  4,  9, 17, 10, 13, 16, 10,  6,  1, 17, 10,  5, 17,  8, 10, 10, 13,\n",
      "          8,  1, 10, 11, 10, 18,  9, 17,  8,  1,  4, 10],\n",
      "        [10,  8, 17, 13, 12,  7, 18, 16,  5,  8,  3,  6,  8, 10, 10,  6, 10,  5,\n",
      "         10, 13, 18, 15, 13, 18,  5,  1, 18, 20, 17, 16]])\n",
      "CDS tensor([[65, 31, 22, 56, 56, 45, 62, 55, 31, 61, 50, 59, 10,  9, 45, 62, 50, 62,\n",
      "         28, 24, 56, 33, 19,  8, 28, 13, 45, 21, 55,  6],\n",
      "        [65, 55, 29, 23, 50, 62, 52, 52, 58, 55, 39, 30, 58, 52, 49, 51, 51, 43,\n",
      "         51, 29, 49, 43,  7, 54, 51, 33, 56, 62, 34,  7],\n",
      "        [65, 51, 59, 43, 42, 25, 30, 10,  9, 56, 58, 46,  9,  5, 38, 41, 29, 25,\n",
      "         22, 33, 62, 29, 45, 13, 49, 43, 46, 33, 54, 59],\n",
      "        [65, 25, 33, 46, 18, 35, 23, 53,  2,  1, 33, 51, 56, 33, 13, 17, 60, 29,\n",
      "          1,  9, 18, 61, 20, 26, 61,  1, 54, 49,  7, 38]])\n"
     ]
    }
   ],
   "source": [
    "dummy_input = (prot, cds)\n",
    "input_names = [\"prot\", \"cds\"]\n",
    "output_names = [\"output\"]\n",
    "model.eval()\n",
    "torch.onnx.export(model, dummy_input, \"test.onnx\", input_names=input_names, output_names=output_names,\n",
    "                export_params=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
