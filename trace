/home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5047: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
Exported graph: graph(%prot : Long(4, 30, strides=[30, 1], requires_grad=0, device=cpu),
      %cds : Long(4, 30, strides=[30, 1], requires_grad=0, device=cpu),
      %prot_encoder.prot_embedding.weight : Float(22, 64, strides=[64, 1], requires_grad=1, device=cpu),
      %prot_encoder.transformer_encoder.layers.0.self_attn.in_proj_bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %prot_encoder.transformer_encoder.layers.0.self_attn.out_proj.weight : Float(64, 64, strides=[64, 1], requires_grad=1, device=cpu),
      %prot_encoder.transformer_encoder.layers.0.self_attn.out_proj.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %prot_encoder.transformer_encoder.layers.0.linear1.bias : Float(256, strides=[1], requires_grad=1, device=cpu),
      %prot_encoder.transformer_encoder.layers.0.linear2.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %prot_encoder.transformer_encoder.layers.0.norm1.weight : Float(64, strides=[1], requires_grad=1, device=cpu),
      %prot_encoder.transformer_encoder.layers.0.norm1.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %prot_encoder.transformer_encoder.layers.0.norm2.weight : Float(64, strides=[1], requires_grad=1, device=cpu),
      %prot_encoder.transformer_encoder.layers.0.norm2.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %codon_decoder.codon_embedding.weight : Float(66, 64, strides=[64, 1], requires_grad=1, device=cpu),
      %codon_decoder.transformer_decoder.layers.0.self_attn.in_proj_bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %codon_decoder.transformer_decoder.layers.0.self_attn.out_proj.weight : Float(64, 64, strides=[64, 1], requires_grad=1, device=cpu),
      %codon_decoder.transformer_decoder.layers.0.self_attn.out_proj.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %codon_decoder.transformer_decoder.layers.0.multihead_attn.out_proj.weight : Float(64, 64, strides=[64, 1], requires_grad=1, device=cpu),
      %codon_decoder.transformer_decoder.layers.0.multihead_attn.out_proj.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %codon_decoder.transformer_decoder.layers.0.linear1.bias : Float(256, strides=[1], requires_grad=1, device=cpu),
      %codon_decoder.transformer_decoder.layers.0.linear2.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %codon_decoder.transformer_decoder.layers.0.norm1.weight : Float(64, strides=[1], requires_grad=1, device=cpu),
      %codon_decoder.transformer_decoder.layers.0.norm1.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %codon_decoder.transformer_decoder.layers.0.norm2.weight : Float(64, strides=[1], requires_grad=1, device=cpu),
      %codon_decoder.transformer_decoder.layers.0.norm2.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %codon_decoder.transformer_decoder.layers.0.norm3.weight : Float(64, strides=[1], requires_grad=1, device=cpu),
      %codon_decoder.transformer_decoder.layers.0.norm3.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %codon_decoder.transformer_decoder.layers.1.self_attn.in_proj_bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %codon_decoder.transformer_decoder.layers.1.self_attn.out_proj.weight : Float(64, 64, strides=[64, 1], requires_grad=1, device=cpu),
      %codon_decoder.transformer_decoder.layers.1.self_attn.out_proj.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %codon_decoder.transformer_decoder.layers.1.multihead_attn.out_proj.weight : Float(64, 64, strides=[64, 1], requires_grad=1, device=cpu),
      %codon_decoder.transformer_decoder.layers.1.multihead_attn.out_proj.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %codon_decoder.transformer_decoder.layers.1.linear1.bias : Float(256, strides=[1], requires_grad=1, device=cpu),
      %codon_decoder.transformer_decoder.layers.1.linear2.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %codon_decoder.transformer_decoder.layers.1.norm1.weight : Float(64, strides=[1], requires_grad=1, device=cpu),
      %codon_decoder.transformer_decoder.layers.1.norm1.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %codon_decoder.transformer_decoder.layers.1.norm2.weight : Float(64, strides=[1], requires_grad=1, device=cpu),
      %codon_decoder.transformer_decoder.layers.1.norm2.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %codon_decoder.transformer_decoder.layers.1.norm3.weight : Float(64, strides=[1], requires_grad=1, device=cpu),
      %codon_decoder.transformer_decoder.layers.1.norm3.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %codon_masker.weight : Float(22, 65, strides=[65, 1], requires_grad=0, device=cpu),
      %linear.bias : Float(65, strides=[1], requires_grad=1, device=cpu),
      %onnx::Add_1121 : Float(1, 30, 64, strides=[32000, 64, 1], requires_grad=0, device=cpu),
      %onnx::MatMul_1122 : Float(64, 192, strides=[1, 64], requires_grad=0, device=cpu),
      %onnx::MatMul_1176 : Float(64, 256, strides=[1, 64], requires_grad=0, device=cpu),
      %onnx::MatMul_1177 : Float(256, 64, strides=[1, 256], requires_grad=0, device=cpu),
      %onnx::MatMul_1179 : Float(64, 192, strides=[1, 64], requires_grad=0, device=cpu),
      %onnx::Add_1242 : Float(64, strides=[1], requires_grad=0, device=cpu),
      %onnx::Add_1244 : Float(128, strides=[1], requires_grad=0, device=cpu),
      %onnx::MatMul_1245 : Float(64, 64, strides=[1, 64], requires_grad=0, device=cpu),
      %onnx::MatMul_1246 : Float(64, 128, strides=[1, 64], requires_grad=0, device=cpu),
      %onnx::MatMul_1300 : Float(64, 256, strides=[1, 64], requires_grad=0, device=cpu),
      %onnx::MatMul_1301 : Float(256, 64, strides=[1, 256], requires_grad=0, device=cpu),
      %onnx::MatMul_1302 : Float(64, 192, strides=[1, 64], requires_grad=0, device=cpu),
      %onnx::Add_1365 : Float(64, strides=[1], requires_grad=0, device=cpu),
      %onnx::Add_1367 : Float(128, strides=[1], requires_grad=0, device=cpu),
      %onnx::MatMul_1368 : Float(64, 64, strides=[1, 64], requires_grad=0, device=cpu),
      %onnx::MatMul_1369 : Float(64, 128, strides=[1, 64], requires_grad=0, device=cpu),
      %onnx::MatMul_1423 : Float(64, 256, strides=[1, 64], requires_grad=0, device=cpu),
      %onnx::MatMul_1424 : Float(256, 64, strides=[1, 256], requires_grad=0, device=cpu),
      %onnx::MatMul_1425 : Float(64, 65, strides=[1, 64], requires_grad=0, device=cpu)):
  %onnx::Add_1178 : Float(1, 30, 64, strides=[32000, 64, 1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Add_1121)
  %/codon_masker/Gather_output_0 : Float(4, 30, 65, strides=[1950, 65, 1], requires_grad=0, device=cpu) = onnx::Gather[onnx_name="/codon_masker/Gather"](%codon_masker.weight, %prot), scope: collage.model.Codon_Predictor::/torch.nn.modules.sparse.Embedding::codon_masker # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:2238:0
  %/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/Constant"](), scope: collage.model.Codon_Predictor::
  %/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/Constant_1"](), scope: collage.model.Codon_Predictor:: # /home/auberon/programming/collage/collage/model.py:134:0
  %/Equal_output_0 : Bool(4, 30, 65, strides=[1950, 65, 1], device=cpu) = onnx::Equal[onnx_name="/Equal"](%/codon_masker/Gather_output_0, %/Constant_1_output_0), scope: collage.model.Codon_Predictor:: # /home/auberon/programming/collage/collage/model.py:134:0
  %/Not_output_0 : Bool(4, 30, 65, strides=[1950, 65, 1], requires_grad=0, device=cpu) = onnx::Not[onnx_name="/Not"](%/Equal_output_0), scope: collage.model.Codon_Predictor:: # /home/auberon/programming/collage/collage/model.py:134:0
  %/Constant_2_output_0 : Double(device=cpu) = onnx::Constant[value={0}, onnx_name="/Constant_2"](), scope: collage.model.Codon_Predictor::
  %/Constant_3_output_0 : Double(device=cpu) = onnx::Constant[value={-inf}, onnx_name="/Constant_3"](), scope: collage.model.Codon_Predictor::
  %/Where_output_0 : Double(4, 30, 65, strides=[1950, 65, 1], requires_grad=0, device=cpu) = onnx::Where[onnx_name="/Where"](%/Not_output_0, %/Constant_2_output_0, %/Constant_3_output_0), scope: collage.model.Codon_Predictor:: # /home/auberon/programming/collage/collage/model.py:134:0
  %/prot_encoder/Constant_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/prot_encoder/Constant"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder # /home/auberon/programming/collage/collage/model.py:57:0
  %/prot_encoder/Equal_output_0 : Bool(4, 30, strides=[30, 1], requires_grad=0, device=cpu) = onnx::Equal[onnx_name="/prot_encoder/Equal"](%prot, %/prot_encoder/Constant_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder # /home/auberon/programming/collage/collage/model.py:57:0
  %/prot_encoder/Cast_output_0 : Bool(4, 30, strides=[30, 1], requires_grad=0, device=cpu) = onnx::Cast[to=9, onnx_name="/prot_encoder/Cast"](%/prot_encoder/Equal_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder # /home/auberon/programming/collage/collage/model.py:57:0
  %/prot_encoder/prot_embedding/Gather_output_0 : Float(4, 30, 64, strides=[1920, 64, 1], requires_grad=1, device=cpu) = onnx::Gather[onnx_name="/prot_encoder/prot_embedding/Gather"](%prot_encoder.prot_embedding.weight, %prot), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.sparse.Embedding::prot_embedding # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:2238:0
  %/prot_encoder/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/prot_encoder/Constant_1"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder # /home/auberon/programming/collage/collage/model.py:58:0
  %/prot_encoder/Mul_output_0 : Float(4, 30, 64, strides=[1920, 64, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name="/prot_encoder/Mul"](%/prot_encoder/prot_embedding/Gather_output_0, %/prot_encoder/Constant_1_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder # /home/auberon/programming/collage/collage/model.py:58:0
  %/prot_encoder/pos_encoder/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/prot_encoder/pos_encoder/Constant"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/collage.model.PositionalEncoding::pos_encoder
  %/prot_encoder/pos_encoder/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/prot_encoder/pos_encoder/Constant_1"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/collage.model.PositionalEncoding::pos_encoder
  %/prot_encoder/pos_encoder/Add_output_0 : Float(4, 30, 64, strides=[1920, 64, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name="/prot_encoder/pos_encoder/Add"](%/prot_encoder/Mul_output_0, %onnx::Add_1121), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/collage.model.PositionalEncoding::pos_encoder # /home/auberon/programming/collage/collage/model.py:36:0
  %/prot_encoder/transformer_encoder/Constant_output_0 : Float(4, 30, strides=[30, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name="/prot_encoder/transformer_encoder/Constant"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5053:0
  %/prot_encoder/transformer_encoder/Cast_output_0 : Bool(4, 30, strides=[30, 1], device=cpu) = onnx::Cast[to=9, onnx_name="/prot_encoder/transformer_encoder/Cast"](%/prot_encoder/Cast_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5054:0
  %/prot_encoder/transformer_encoder/Constant_1_output_0 : Float(device=cpu) = onnx::Constant[value={-inf}, onnx_name="/prot_encoder/transformer_encoder/Constant_1"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5054:0
  %/prot_encoder/transformer_encoder/Where_output_0 : Float(4, 30, strides=[30, 1], requires_grad=0, device=cpu) = onnx::Where[onnx_name="/prot_encoder/transformer_encoder/Where"](%/prot_encoder/transformer_encoder/Cast_output_0, %/prot_encoder/transformer_encoder/Constant_1_output_0, %/prot_encoder/transformer_encoder/Constant_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5054:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Transpose_output_0 : Float(30, 4, 64, strides=[64, 1920, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Transpose"](%/prot_encoder/pos_encoder/Add_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:1209:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/MatMul_output_0 : Float(30, 4, 192, strides=[768, 192, 1], device=cpu) = onnx::MatMul[onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/MatMul"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Transpose_output_0, %onnx::MatMul_1122), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4810:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Add_output_0 : Float(30, 4, 192, strides=[768, 192, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Add"](%prot_encoder.transformer_encoder.layers.0.self_attn.in_proj_bias, %/prot_encoder/transformer_encoder/layers.0/self_attn/MatMul_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4810:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  3  64 [ CPULongType{2} ], onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_1_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_1"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_2_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_2"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Mod_output_0 : Long(1, strides=[1], device=cpu) = onnx::Mod[onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Mod"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_1_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_2_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Shape"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Add_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_3"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_4"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_output_0 : Long(1, strides=[1], device=cpu) = onnx::Reshape[onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Mod_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_4_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Slice_output_0 : Long(*, device=cpu) = onnx::Slice[onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Slice"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Shape_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_3_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_5"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Add_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Add[onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Add_1"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Mod_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_5_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_6"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Reshape[onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_1"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Add_1_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_6_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_7"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Slice_1_output_0 : Long(*, device=cpu) = onnx::Slice[onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Slice_1"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Shape_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_1_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_7_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Concat_output_0 : Long(*, device=cpu) = onnx::Concat[axis=0, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Concat"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Slice_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Slice_1_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_2_output_0 : Float(30, 4, 3, 64, strides=[768, 192, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_2"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Add_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Concat_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_8"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4812:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Unsqueeze_output_0 : Float(1, 30, 4, 3, 64, strides=[23040, 768, 192, 64, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze[onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Unsqueeze"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_2_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_8_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4812:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Transpose_1_output_0 : Float(3, 30, 4, 1, 64, strides=[64, 768, 192, 23040, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[3, 1, 2, 0, 4], onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Transpose_1"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Unsqueeze_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4812:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_9"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4812:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Squeeze_output_0 : Float(3, 30, 4, 64, strides=[7680, 256, 64, 1], requires_grad=1, device=cpu) = onnx::Squeeze[onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Squeeze"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Transpose_1_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_9_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4812:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Gather_output_0 : Float(30, 4, 64, strides=[256, 64, 1], requires_grad=1, device=cpu) = onnx::Gather[axis=0, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Gather"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Squeeze_output_0, %/Constant_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4813:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Gather_1_output_0 : Float(30, 4, 64, strides=[256, 64, 1], requires_grad=1, device=cpu) = onnx::Gather[axis=0, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Gather_1"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Squeeze_output_0, %/prot_encoder/pos_encoder/Constant_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4813:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Gather_2_output_0 : Float(30, 4, 64, strides=[256, 64, 1], requires_grad=1, device=cpu) = onnx::Gather[axis=0, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Gather_2"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Squeeze_output_0, %/prot_encoder/pos_encoder/Constant_1_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4813:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_10_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 30  16  16 [ CPULongType{3} ], onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_10"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5315:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_3_output_0 : Float(30, 16, 16, strides=[256, 16, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_3"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Gather_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_10_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5315:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Transpose_2_output_0 : Float(16, 30, 16, strides=[16, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Transpose_2"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_3_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5315:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_11_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 30  16  16 [ CPULongType{3} ], onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_11"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5317:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_4_output_0 : Float(30, 16, 16, strides=[256, 16, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_4"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Gather_1_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_11_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5317:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Transpose_3_output_0 : Float(16, 30, 16, strides=[16, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Transpose_3"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_4_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5317:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_12_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 30  16  16 [ CPULongType{3} ], onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_12"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5326:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_5_output_0 : Float(30, 16, 16, strides=[256, 16, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_5"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Gather_2_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_12_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5326:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Transpose_4_output_0 : Float(16, 30, 16, strides=[16, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Transpose_4"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_5_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5326:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_13_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  4   1   1  30 [ CPULongType{4} ], onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_13"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5352:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_6_output_0 : Float(4, 1, 1, 30, strides=[30, 30, 30, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_6"](%/prot_encoder/transformer_encoder/Where_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_13_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5352:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_14_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value=-1  4 -1 -1 [ CPULongType{4} ], onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_14"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_15"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/ConstantOfShape_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/ConstantOfShape"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_15_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_16_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_16"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Mul_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Mul"](%/prot_encoder/transformer_encoder/layers.0/self_attn/ConstantOfShape_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_16_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_17_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=-1  4 -1 -1 [ CPULongType{4} ], onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_17"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Equal_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Equal"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_17_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Mul_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Where_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Where"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Equal_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/ConstantOfShape_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_14_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Expand_output_0 : Float(4, 4, 1, 30, strides=[30, 0, 30, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Expand"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_6_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Where_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_18_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 16   1  30 [ CPULongType{3} ], onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_18"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_7_output_0 : Float(16, 1, 30, strides=[30, 30, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_7"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Expand_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_18_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_19_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  4   4  -1  30 [ CPULongType{4} ], onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_19"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5405:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_8_output_0 : Float(4, 4, 1, 30, strides=[120, 30, 30, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_8"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_7_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_19_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5405:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_20_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  4   4  30  16 [ CPULongType{4} ], onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_20"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5407:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_9_output_0 : Float(4, 4, 30, 16, strides=[64, 16, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_9"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Transpose_2_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_20_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5407:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_21_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  4   4  30  16 [ CPULongType{4} ], onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_21"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5408:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_22_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  4   4  30  16 [ CPULongType{4} ], onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_22"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5409:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_10_output_0 : Float(4, 4, 30, 16, strides=[64, 16, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_10"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Transpose_3_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_21_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5408:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_11_output_0 : Float(4, 4, 30, 16, strides=[64, 16, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_11"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Transpose_4_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_22_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5409:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Shape_1"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_9_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_23"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_24"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Slice_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Slice[onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Slice_2"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Shape_1_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_23_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_24_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Cast_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Cast"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Slice_2_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Sqrt_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Sqrt"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Cast_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_25_output_0 : Float(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_25"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Div_output_0 : Float(1, strides=[1], device=cpu) = onnx::Div[onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Div"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_25_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Sqrt_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Transpose_5_output_0 : Float(4, 4, 16, 30, strides=[1920, 480, 30, 1], device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Transpose_5"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_10_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Sqrt_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Sqrt_1"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Div_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Mul_1_output_0 : Float(4, 4, 30, 16, strides=[1920, 480, 16, 1], device=cpu) = onnx::Mul[onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Mul_1"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_9_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Sqrt_1_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Sqrt_2_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Sqrt_2"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Div_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Mul_2_output_0 : Float(4, 4, 16, 30, strides=[1920, 480, 30, 1], device=cpu) = onnx::Mul[onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Mul_2"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Transpose_5_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Sqrt_2_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/MatMul_1_output_0 : Float(4, 4, 30, 30, strides=[3600, 900, 30, 1], device=cpu) = onnx::MatMul[onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/MatMul_1"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Mul_1_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Mul_2_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Add_2_output_0 : Float(4, 4, 30, 30, strides=[3600, 900, 30, 1], device=cpu) = onnx::Add[onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Add_2"](%/prot_encoder/transformer_encoder/layers.0/self_attn/MatMul_1_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_8_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Softmax_output_0 : Float(4, 4, 30, 30, strides=[3600, 900, 30, 1], device=cpu) = onnx::Softmax[axis=-1, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Softmax"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Add_2_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/MatMul_2_output_0 : Float(4, 4, 30, 16, strides=[1920, 480, 16, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/MatMul_2"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Softmax_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_11_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Transpose_6_output_0 : Float(30, 4, 4, 16, strides=[256, 64, 16, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[2, 0, 1, 3], onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Transpose_6"](%/prot_encoder/transformer_encoder/layers.0/self_attn/MatMul_2_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5412:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_26_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 120   64 [ CPULongType{2} ], onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_26"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5412:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_12_output_0 : Float(120, 64, strides=[64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_12"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Transpose_6_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_26_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5412:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Gemm_output_0 : Float(120, 64, strides=[64, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Gemm"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_12_output_0, %prot_encoder.transformer_encoder.layers.0.self_attn.out_proj.weight, %prot_encoder.transformer_encoder.layers.0.self_attn.out_proj.bias), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5414:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_27_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 30   4  64 [ CPULongType{3} ], onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_27"](), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5415:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_13_output_0 : Float(30, 4, 64, strides=[256, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_13"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Gemm_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Constant_27_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5415:0
  %/prot_encoder/transformer_encoder/layers.0/self_attn/Transpose_7_output_0 : Float(4, 30, 64, strides=[64, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/prot_encoder/transformer_encoder/layers.0/self_attn/Transpose_7"](%/prot_encoder/transformer_encoder/layers.0/self_attn/Reshape_13_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:1243:0
  %/prot_encoder/transformer_encoder/layers.0/Add_output_0 : Float(4, 30, 64, strides=[1920, 64, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name="/prot_encoder/transformer_encoder/layers.0/Add"](%/prot_encoder/pos_encoder/Add_output_0, %/prot_encoder/transformer_encoder/layers.0/self_attn/Transpose_7_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:618:0
  %/prot_encoder/transformer_encoder/layers.0/norm1/LayerNormalization_output_0 : Float(4, 30, 64, strides=[1920, 64, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/prot_encoder/transformer_encoder/layers.0/norm1/LayerNormalization"](%/prot_encoder/transformer_encoder/layers.0/Add_output_0, %prot_encoder.transformer_encoder.layers.0.norm1.weight, %prot_encoder.transformer_encoder.layers.0.norm1.bias), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm1 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:2548:0
  %/prot_encoder/transformer_encoder/layers.0/linear1/MatMul_output_0 : Float(4, 30, 256, strides=[7680, 256, 1], device=cpu) = onnx::MatMul[onnx_name="/prot_encoder/transformer_encoder/layers.0/linear1/MatMul"](%/prot_encoder/transformer_encoder/layers.0/norm1/LayerNormalization_output_0, %onnx::MatMul_1176), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.linear.Linear::linear1 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0
  %/prot_encoder/transformer_encoder/layers.0/linear1/Add_output_0 : Float(4, 30, 256, strides=[7680, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name="/prot_encoder/transformer_encoder/layers.0/linear1/Add"](%prot_encoder.transformer_encoder.layers.0.linear1.bias, %/prot_encoder/transformer_encoder/layers.0/linear1/MatMul_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.linear.Linear::linear1 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0
  %/prot_encoder/transformer_encoder/layers.0/Relu_output_0 : Float(4, 30, 256, strides=[7680, 256, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name="/prot_encoder/transformer_encoder/layers.0/Relu"](%/prot_encoder/transformer_encoder/layers.0/linear1/Add_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:1475:0
  %/prot_encoder/transformer_encoder/layers.0/linear2/MatMul_output_0 : Float(4, 30, 64, strides=[1920, 64, 1], device=cpu) = onnx::MatMul[onnx_name="/prot_encoder/transformer_encoder/layers.0/linear2/MatMul"](%/prot_encoder/transformer_encoder/layers.0/Relu_output_0, %onnx::MatMul_1177), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.linear.Linear::linear2 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0
  %/prot_encoder/transformer_encoder/layers.0/linear2/Add_output_0 : Float(4, 30, 64, strides=[1920, 64, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name="/prot_encoder/transformer_encoder/layers.0/linear2/Add"](%prot_encoder.transformer_encoder.layers.0.linear2.bias, %/prot_encoder/transformer_encoder/layers.0/linear2/MatMul_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.linear.Linear::linear2 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0
  %/prot_encoder/transformer_encoder/layers.0/Add_1_output_0 : Float(4, 30, 64, strides=[1920, 64, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name="/prot_encoder/transformer_encoder/layers.0/Add_1"](%/prot_encoder/transformer_encoder/layers.0/norm1/LayerNormalization_output_0, %/prot_encoder/transformer_encoder/layers.0/linear2/Add_output_0), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:619:0
  %/prot_encoder/transformer_encoder/layers.0/norm2/LayerNormalization_output_0 : Float(4, 30, 64, strides=[1920, 64, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/prot_encoder/transformer_encoder/layers.0/norm2/LayerNormalization"](%/prot_encoder/transformer_encoder/layers.0/Add_1_output_0, %prot_encoder.transformer_encoder.layers.0.norm2.weight, %prot_encoder.transformer_encoder.layers.0.norm2.bias), scope: collage.model.Codon_Predictor::/collage.model.Prot_Encoder::prot_encoder/torch.nn.modules.transformer.TransformerEncoder::transformer_encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm2 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:2548:0
  %/codon_decoder/Constant_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/codon_decoder/Constant"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder # /home/auberon/programming/collage/collage/model.py:86:0
  %/codon_decoder/Equal_output_0 : Bool(4, 30, strides=[30, 1], requires_grad=0, device=cpu) = onnx::Equal[onnx_name="/codon_decoder/Equal"](%cds, %/codon_decoder/Constant_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder # /home/auberon/programming/collage/collage/model.py:86:0
  %/codon_decoder/Cast_output_0 : Bool(4, 30, strides=[30, 1], requires_grad=0, device=cpu) = onnx::Cast[to=9, onnx_name="/codon_decoder/Cast"](%/codon_decoder/Equal_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder # /home/auberon/programming/collage/collage/model.py:86:0
  %/codon_decoder/Constant_1_output_0 : Bool(30, 30, strides=[30, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name="/codon_decoder/Constant_1"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder # /home/auberon/programming/collage/collage/model.py:81:0
  %/codon_decoder/Trilu_output_0 : Bool(30, 30, strides=[30, 1], requires_grad=0, device=cpu) = onnx::Trilu[upper=0, onnx_name="/codon_decoder/Trilu"](%/codon_decoder/Constant_1_output_0, %/Constant_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder # /home/auberon/programming/collage/collage/model.py:82:0
  %/codon_decoder/Where_output_0 : Double(30, 30, strides=[30, 1], requires_grad=0, device=cpu) = onnx::Where[onnx_name="/codon_decoder/Where"](%/codon_decoder/Trilu_output_0, %/Constant_2_output_0, %/Constant_3_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder # /home/auberon/programming/collage/collage/model.py:83:0
  %/codon_decoder/Cast_1_output_0 : Float(30, 30, strides=[30, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name="/codon_decoder/Cast_1"](%/codon_decoder/Where_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder # /home/auberon/programming/collage/collage/model.py:88:0
  %/codon_decoder/codon_embedding/Gather_output_0 : Float(4, 30, 64, strides=[1920, 64, 1], requires_grad=1, device=cpu) = onnx::Gather[onnx_name="/codon_decoder/codon_embedding/Gather"](%codon_decoder.codon_embedding.weight, %cds), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.sparse.Embedding::codon_embedding # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:2238:0
  %/codon_decoder/pos_encoder/Add_output_0 : Float(4, 30, 64, strides=[1920, 64, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name="/codon_decoder/pos_encoder/Add"](%/codon_decoder/codon_embedding/Gather_output_0, %onnx::Add_1178), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/collage.model.PositionalEncoding::pos_encoder # /home/auberon/programming/collage/collage/model.py:36:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_output_0 : Float(4, 30, strides=[30, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5053:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Cast_output_0 : Bool(4, 30, strides=[30, 1], device=cpu) = onnx::Cast[to=9, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Cast"](%/codon_decoder/Cast_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5054:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_1_output_0 : Float(device=cpu) = onnx::Constant[value={-inf}, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_1"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5054:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Where_output_0 : Float(4, 30, strides=[30, 1], requires_grad=0, device=cpu) = onnx::Where[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Where"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Cast_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_1_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5054:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Transpose_output_0 : Float(30, 4, 64, strides=[64, 1920, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Transpose"](%/codon_decoder/pos_encoder/Add_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:1209:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/MatMul_output_0 : Float(30, 4, 192, strides=[768, 192, 1], device=cpu) = onnx::MatMul[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/MatMul"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Transpose_output_0, %onnx::MatMul_1179), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4810:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Add_output_0 : Float(30, 4, 192, strides=[768, 192, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Add"](%codon_decoder.transformer_decoder.layers.0.self_attn.in_proj_bias, %/codon_decoder/transformer_decoder/layers.0/self_attn/MatMul_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4810:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_2_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  3  64 [ CPULongType{2} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_2"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_3"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_4"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Mod_output_0 : Long(1, strides=[1], device=cpu) = onnx::Mod[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Mod"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_3_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_4_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Shape"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Add_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_5"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_6"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_output_0 : Long(1, strides=[1], device=cpu) = onnx::Reshape[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Mod_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_6_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Slice_output_0 : Long(*, device=cpu) = onnx::Slice[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Slice"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Shape_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_5_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_7"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Add_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Add[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Add_1"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Mod_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_7_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_8"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Reshape[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_1"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Add_1_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_8_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_9"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Slice_1_output_0 : Long(*, device=cpu) = onnx::Slice[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Slice_1"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Shape_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_1_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_9_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Concat_output_0 : Long(*, device=cpu) = onnx::Concat[axis=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Concat"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Slice_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_2_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Slice_1_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_2_output_0 : Float(30, 4, 3, 64, strides=[768, 192, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_2"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Add_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Concat_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_10"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4812:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Unsqueeze_output_0 : Float(1, 30, 4, 3, 64, strides=[23040, 768, 192, 64, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Unsqueeze"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_2_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_10_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4812:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Transpose_1_output_0 : Float(3, 30, 4, 1, 64, strides=[64, 768, 192, 23040, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[3, 1, 2, 0, 4], onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Transpose_1"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Unsqueeze_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4812:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_11"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4812:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Squeeze_output_0 : Float(3, 30, 4, 64, strides=[7680, 256, 64, 1], requires_grad=1, device=cpu) = onnx::Squeeze[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Squeeze"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Transpose_1_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_11_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4812:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Gather_output_0 : Float(30, 4, 64, strides=[256, 64, 1], requires_grad=1, device=cpu) = onnx::Gather[axis=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Gather"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Squeeze_output_0, %/Constant_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4813:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Gather_1_output_0 : Float(30, 4, 64, strides=[256, 64, 1], requires_grad=1, device=cpu) = onnx::Gather[axis=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Gather_1"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Squeeze_output_0, %/prot_encoder/pos_encoder/Constant_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4813:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Gather_2_output_0 : Float(30, 4, 64, strides=[256, 64, 1], requires_grad=1, device=cpu) = onnx::Gather[axis=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Gather_2"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Squeeze_output_0, %/prot_encoder/pos_encoder/Constant_1_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4813:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_12"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5290:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Unsqueeze_1_output_0 : Float(1, 30, 30, strides=[900, 30, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Unsqueeze_1"](%/codon_decoder/Cast_1_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_12_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5290:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_13_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 30  16  16 [ CPULongType{3} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_13"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5315:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_3_output_0 : Float(30, 16, 16, strides=[256, 16, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_3"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Gather_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_13_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5315:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Transpose_2_output_0 : Float(16, 30, 16, strides=[16, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Transpose_2"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_3_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5315:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_14_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 30  16  16 [ CPULongType{3} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_14"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5317:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_4_output_0 : Float(30, 16, 16, strides=[256, 16, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_4"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Gather_1_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_14_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5317:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Transpose_3_output_0 : Float(16, 30, 16, strides=[16, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Transpose_3"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_4_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5317:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_15_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 30  16  16 [ CPULongType{3} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_15"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5326:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_5_output_0 : Float(30, 16, 16, strides=[256, 16, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_5"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Gather_2_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_15_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5326:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Transpose_4_output_0 : Float(16, 30, 16, strides=[16, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Transpose_4"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_5_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5326:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_16_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  4   1   1  30 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_16"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5352:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_6_output_0 : Float(4, 1, 1, 30, strides=[30, 30, 30, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_6"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Where_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_16_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5352:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_17_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value=-1  4 -1 -1 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_17"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_18_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_18"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/ConstantOfShape_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/ConstantOfShape"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_18_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_19_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_19"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Mul_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Mul"](%/codon_decoder/transformer_decoder/layers.0/self_attn/ConstantOfShape_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_19_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_20_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=-1  4 -1 -1 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_20"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Equal_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Equal"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_20_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Mul_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Where_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Where_1"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Equal_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/ConstantOfShape_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_17_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Expand_output_0 : Float(4, 4, 1, 30, strides=[30, 0, 30, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Expand"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_6_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Where_1_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_21_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 16   1  30 [ CPULongType{3} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_21"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_7_output_0 : Float(16, 1, 30, strides=[30, 30, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_7"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Expand_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_21_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Add_2_output_0 : Float(16, 30, 30, strides=[900, 30, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Add_2"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Unsqueeze_1_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_7_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5357:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_22_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  4   4  -1  30 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_22"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5405:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_8_output_0 : Float(4, 4, 30, 30, strides=[3600, 900, 30, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_8"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Add_2_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_22_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5405:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_23_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  4   4  30  16 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_23"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5407:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_9_output_0 : Float(4, 4, 30, 16, strides=[64, 16, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_9"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Transpose_2_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_23_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5407:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_24_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  4   4  30  16 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_24"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5408:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_25_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  4   4  30  16 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_25"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5409:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_10_output_0 : Float(4, 4, 30, 16, strides=[64, 16, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_10"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Transpose_3_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_24_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5408:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_11_output_0 : Float(4, 4, 30, 16, strides=[64, 16, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_11"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Transpose_4_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_25_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5409:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Shape_1"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_9_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_26"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_27"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Slice_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Slice[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Slice_2"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Shape_1_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_26_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_27_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Cast_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Cast_1"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Slice_2_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Sqrt_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Sqrt"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Cast_1_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_28_output_0 : Float(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_28"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Div_output_0 : Float(1, strides=[1], device=cpu) = onnx::Div[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Div"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_28_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Sqrt_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Transpose_5_output_0 : Float(4, 4, 16, 30, strides=[1920, 480, 30, 1], device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Transpose_5"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_10_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Sqrt_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Sqrt_1"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Div_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Mul_1_output_0 : Float(4, 4, 30, 16, strides=[1920, 480, 16, 1], device=cpu) = onnx::Mul[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Mul_1"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_9_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Sqrt_1_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Sqrt_2_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Sqrt_2"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Div_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Mul_2_output_0 : Float(4, 4, 16, 30, strides=[1920, 480, 30, 1], device=cpu) = onnx::Mul[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Mul_2"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Transpose_5_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Sqrt_2_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/MatMul_1_output_0 : Float(4, 4, 30, 30, strides=[3600, 900, 30, 1], device=cpu) = onnx::MatMul[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/MatMul_1"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Mul_1_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Mul_2_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Add_3_output_0 : Float(4, 4, 30, 30, strides=[3600, 900, 30, 1], device=cpu) = onnx::Add[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Add_3"](%/codon_decoder/transformer_decoder/layers.0/self_attn/MatMul_1_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_8_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Softmax_output_0 : Float(4, 4, 30, 30, strides=[3600, 900, 30, 1], device=cpu) = onnx::Softmax[axis=-1, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Softmax"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Add_3_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/MatMul_2_output_0 : Float(4, 4, 30, 16, strides=[1920, 480, 16, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/MatMul_2"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Softmax_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_11_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Transpose_6_output_0 : Float(30, 4, 4, 16, strides=[256, 64, 16, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[2, 0, 1, 3], onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Transpose_6"](%/codon_decoder/transformer_decoder/layers.0/self_attn/MatMul_2_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5412:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_29_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 120   64 [ CPULongType{2} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_29"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5412:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_12_output_0 : Float(120, 64, strides=[64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_12"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Transpose_6_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_29_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5412:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Gemm_output_0 : Float(120, 64, strides=[64, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Gemm"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_12_output_0, %codon_decoder.transformer_decoder.layers.0.self_attn.out_proj.weight, %codon_decoder.transformer_decoder.layers.0.self_attn.out_proj.bias), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5414:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_30_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 30   4  64 [ CPULongType{3} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_30"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5415:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_13_output_0 : Float(30, 4, 64, strides=[256, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_13"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Gemm_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Constant_30_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5415:0
  %/codon_decoder/transformer_decoder/layers.0/self_attn/Transpose_7_output_0 : Float(4, 30, 64, strides=[64, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/codon_decoder/transformer_decoder/layers.0/self_attn/Transpose_7"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Reshape_13_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:1243:0
  %/codon_decoder/transformer_decoder/layers.0/Add_output_0 : Float(4, 30, 64, strides=[1920, 64, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name="/codon_decoder/transformer_decoder/layers.0/Add"](%/codon_decoder/pos_encoder/Add_output_0, %/codon_decoder/transformer_decoder/layers.0/self_attn/Transpose_7_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:755:0
  %/codon_decoder/transformer_decoder/layers.0/norm1/LayerNormalization_output_0 : Float(4, 30, 64, strides=[1920, 64, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/codon_decoder/transformer_decoder/layers.0/norm1/LayerNormalization"](%/codon_decoder/transformer_decoder/layers.0/Add_output_0, %codon_decoder.transformer_decoder.layers.0.norm1.weight, %codon_decoder.transformer_decoder.layers.0.norm1.bias), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm1 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:2548:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_output_0 : Float(4, 30, strides=[30, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5053:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Cast_output_0 : Bool(4, 30, strides=[30, 1], device=cpu) = onnx::Cast[to=9, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Cast"](%/prot_encoder/Cast_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5054:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_1_output_0 : Float(device=cpu) = onnx::Constant[value={-inf}, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_1"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5054:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Where_output_0 : Float(4, 30, strides=[30, 1], requires_grad=0, device=cpu) = onnx::Where[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Where"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Cast_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_1_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5054:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose_output_0 : Float(30, 4, 64, strides=[64, 1920, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose"](%/codon_decoder/transformer_decoder/layers.0/norm1/LayerNormalization_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:1211:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose_1_output_0 : Float(30, 4, 64, strides=[64, 1920, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose_1"](%/prot_encoder/transformer_encoder/layers.0/norm2/LayerNormalization_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:1211:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/MatMul_output_0 : Float(30, 4, 64, strides=[256, 64, 1], device=cpu) = onnx::MatMul[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/MatMul"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose_output_0, %onnx::MatMul_1245), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4821:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Add_output_0 : Float(30, 4, 64, strides=[256, 64, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Add"](%onnx::Add_1242, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/MatMul_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4821:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/MatMul_1_output_0 : Float(30, 4, 128, strides=[512, 128, 1], device=cpu) = onnx::MatMul[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/MatMul_1"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose_1_output_0, %onnx::MatMul_1246), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4822:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Add_1_output_0 : Float(30, 4, 128, strides=[512, 128, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Add_1"](%onnx::Add_1244, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/MatMul_1_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4822:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_2_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  2  64 [ CPULongType{2} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_2"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_3"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_4"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Mod_output_0 : Long(1, strides=[1], device=cpu) = onnx::Mod[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Mod"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_3_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_4_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Shape"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Add_1_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_5"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_6"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_output_0 : Long(1, strides=[1], device=cpu) = onnx::Reshape[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Mod_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_6_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Slice_output_0 : Long(*, device=cpu) = onnx::Slice[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Slice"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Shape_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_5_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_7"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Add_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Add[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Add_2"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Mod_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_7_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_8"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Reshape[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_1"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Add_2_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_8_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_9"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Slice_1_output_0 : Long(*, device=cpu) = onnx::Slice[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Slice_1"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Shape_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_1_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_9_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Concat_output_0 : Long(*, device=cpu) = onnx::Concat[axis=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Concat"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Slice_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_2_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Slice_1_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_2_output_0 : Float(30, 4, 2, 64, strides=[512, 128, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_2"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Add_1_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Concat_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_10"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4824:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Unsqueeze_output_0 : Float(1, 30, 4, 2, 64, strides=[15360, 512, 128, 64, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Unsqueeze"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_2_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_10_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4824:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose_2_output_0 : Float(2, 30, 4, 1, 64, strides=[64, 512, 128, 15360, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[3, 1, 2, 0, 4], onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose_2"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Unsqueeze_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4824:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_11"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4824:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Squeeze_output_0 : Float(2, 30, 4, 64, strides=[7680, 256, 64, 1], requires_grad=1, device=cpu) = onnx::Squeeze[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Squeeze"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose_2_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_11_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4824:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Gather_output_0 : Float(30, 4, 64, strides=[256, 64, 1], requires_grad=1, device=cpu) = onnx::Gather[axis=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Gather"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Squeeze_output_0, %/Constant_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4825:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Gather_1_output_0 : Float(30, 4, 64, strides=[256, 64, 1], requires_grad=1, device=cpu) = onnx::Gather[axis=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Gather_1"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Squeeze_output_0, %/prot_encoder/pos_encoder/Constant_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4825:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_12_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 30  16  16 [ CPULongType{3} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_12"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5315:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_3_output_0 : Float(30, 16, 16, strides=[256, 16, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_3"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Add_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_12_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5315:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose_3_output_0 : Float(16, 30, 16, strides=[16, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose_3"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_3_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5315:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_13_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 30  16  16 [ CPULongType{3} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_13"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5317:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_4_output_0 : Float(30, 16, 16, strides=[256, 16, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_4"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Gather_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_13_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5317:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose_4_output_0 : Float(16, 30, 16, strides=[16, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose_4"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_4_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5317:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_14_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 30  16  16 [ CPULongType{3} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_14"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5326:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_5_output_0 : Float(30, 16, 16, strides=[256, 16, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_5"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Gather_1_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_14_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5326:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose_5_output_0 : Float(16, 30, 16, strides=[16, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose_5"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_5_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5326:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_15_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  4   1   1  30 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_15"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5352:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_6_output_0 : Float(4, 1, 1, 30, strides=[30, 30, 30, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_6"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Where_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_15_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5352:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_16_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value=-1  4 -1 -1 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_16"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_17"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/ConstantOfShape_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/ConstantOfShape"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_17_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_18"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Mul_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Mul"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/ConstantOfShape_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_18_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_19_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=-1  4 -1 -1 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_19"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Equal_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Equal"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_19_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Mul_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Where_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Where_1"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Equal_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/ConstantOfShape_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_16_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Expand_output_0 : Float(4, 4, 1, 30, strides=[30, 0, 30, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Expand"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_6_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Where_1_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_20_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 16   1  30 [ CPULongType{3} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_20"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_7_output_0 : Float(16, 1, 30, strides=[30, 30, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_7"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Expand_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_20_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_21_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  4   4  -1  30 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_21"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5405:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_8_output_0 : Float(4, 4, 1, 30, strides=[120, 30, 30, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_8"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_7_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_21_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5405:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_22_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  4   4  30  16 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_22"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5407:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_9_output_0 : Float(4, 4, 30, 16, strides=[64, 16, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_9"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose_3_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_22_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5407:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_23_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  4   4  30  16 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_23"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5408:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_24_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  4   4  30  16 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_24"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5409:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_10_output_0 : Float(4, 4, 30, 16, strides=[64, 16, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_10"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose_4_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_23_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5408:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_11_output_0 : Float(4, 4, 30, 16, strides=[64, 16, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_11"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose_5_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_24_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5409:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Shape_1"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_9_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_25"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_26"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Slice_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Slice[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Slice_2"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Shape_1_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_25_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_26_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Cast_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Cast_1"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Slice_2_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Sqrt_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Sqrt"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Cast_1_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_27_output_0 : Float(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_27"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Div_output_0 : Float(1, strides=[1], device=cpu) = onnx::Div[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Div"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_27_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Sqrt_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose_6_output_0 : Float(4, 4, 16, 30, strides=[1920, 480, 30, 1], device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose_6"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_10_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Sqrt_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Sqrt_1"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Div_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Mul_1_output_0 : Float(4, 4, 30, 16, strides=[1920, 480, 16, 1], device=cpu) = onnx::Mul[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Mul_1"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_9_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Sqrt_1_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Sqrt_2_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Sqrt_2"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Div_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Mul_2_output_0 : Float(4, 4, 16, 30, strides=[1920, 480, 30, 1], device=cpu) = onnx::Mul[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Mul_2"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose_6_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Sqrt_2_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/MatMul_2_output_0 : Float(4, 4, 30, 30, strides=[3600, 900, 30, 1], device=cpu) = onnx::MatMul[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/MatMul_2"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Mul_1_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Mul_2_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Add_3_output_0 : Float(4, 4, 30, 30, strides=[3600, 900, 30, 1], device=cpu) = onnx::Add[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Add_3"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/MatMul_2_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_8_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Softmax_output_0 : Float(4, 4, 30, 30, strides=[3600, 900, 30, 1], device=cpu) = onnx::Softmax[axis=-1, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Softmax"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Add_3_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/MatMul_3_output_0 : Float(4, 4, 30, 16, strides=[1920, 480, 16, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/MatMul_3"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Softmax_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_11_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose_7_output_0 : Float(30, 4, 4, 16, strides=[256, 64, 16, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[2, 0, 1, 3], onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose_7"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/MatMul_3_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5412:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_28_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 120   64 [ CPULongType{2} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_28"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5412:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_12_output_0 : Float(120, 64, strides=[64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_12"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose_7_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_28_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5412:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Gemm_output_0 : Float(120, 64, strides=[64, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Gemm"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_12_output_0, %codon_decoder.transformer_decoder.layers.0.multihead_attn.out_proj.weight, %codon_decoder.transformer_decoder.layers.0.multihead_attn.out_proj.bias), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5414:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_29_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 30   4  64 [ CPULongType{3} ], onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_29"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5415:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_13_output_0 : Float(30, 4, 64, strides=[256, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_13"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Gemm_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Constant_29_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5415:0
  %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose_8_output_0 : Float(4, 30, 64, strides=[64, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose_8"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Reshape_13_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:1243:0
  %/codon_decoder/transformer_decoder/layers.0/Add_1_output_0 : Float(4, 30, 64, strides=[1920, 64, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name="/codon_decoder/transformer_decoder/layers.0/Add_1"](%/codon_decoder/transformer_decoder/layers.0/norm1/LayerNormalization_output_0, %/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose_8_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:756:0
  %/codon_decoder/transformer_decoder/layers.0/norm2/LayerNormalization_output_0 : Float(4, 30, 64, strides=[1920, 64, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/codon_decoder/transformer_decoder/layers.0/norm2/LayerNormalization"](%/codon_decoder/transformer_decoder/layers.0/Add_1_output_0, %codon_decoder.transformer_decoder.layers.0.norm2.weight, %codon_decoder.transformer_decoder.layers.0.norm2.bias), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm2 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:2548:0
  %/codon_decoder/transformer_decoder/layers.0/linear1/MatMul_output_0 : Float(4, 30, 256, strides=[7680, 256, 1], device=cpu) = onnx::MatMul[onnx_name="/codon_decoder/transformer_decoder/layers.0/linear1/MatMul"](%/codon_decoder/transformer_decoder/layers.0/norm2/LayerNormalization_output_0, %onnx::MatMul_1300), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.linear.Linear::linear1 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0
  %/codon_decoder/transformer_decoder/layers.0/linear1/Add_output_0 : Float(4, 30, 256, strides=[7680, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name="/codon_decoder/transformer_decoder/layers.0/linear1/Add"](%codon_decoder.transformer_decoder.layers.0.linear1.bias, %/codon_decoder/transformer_decoder/layers.0/linear1/MatMul_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.linear.Linear::linear1 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0
  %/codon_decoder/transformer_decoder/layers.0/Relu_output_0 : Float(4, 30, 256, strides=[7680, 256, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name="/codon_decoder/transformer_decoder/layers.0/Relu"](%/codon_decoder/transformer_decoder/layers.0/linear1/Add_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:1475:0
  %/codon_decoder/transformer_decoder/layers.0/linear2/MatMul_output_0 : Float(4, 30, 64, strides=[1920, 64, 1], device=cpu) = onnx::MatMul[onnx_name="/codon_decoder/transformer_decoder/layers.0/linear2/MatMul"](%/codon_decoder/transformer_decoder/layers.0/Relu_output_0, %onnx::MatMul_1301), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.linear.Linear::linear2 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0
  %/codon_decoder/transformer_decoder/layers.0/linear2/Add_output_0 : Float(4, 30, 64, strides=[1920, 64, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name="/codon_decoder/transformer_decoder/layers.0/linear2/Add"](%codon_decoder.transformer_decoder.layers.0.linear2.bias, %/codon_decoder/transformer_decoder/layers.0/linear2/MatMul_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.linear.Linear::linear2 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0
  %/codon_decoder/transformer_decoder/layers.0/Add_2_output_0 : Float(4, 30, 64, strides=[1920, 64, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name="/codon_decoder/transformer_decoder/layers.0/Add_2"](%/codon_decoder/transformer_decoder/layers.0/norm2/LayerNormalization_output_0, %/codon_decoder/transformer_decoder/layers.0/linear2/Add_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:757:0
  %/codon_decoder/transformer_decoder/layers.0/norm3/LayerNormalization_output_0 : Float(4, 30, 64, strides=[1920, 64, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/codon_decoder/transformer_decoder/layers.0/norm3/LayerNormalization"](%/codon_decoder/transformer_decoder/layers.0/Add_2_output_0, %codon_decoder.transformer_decoder.layers.0.norm3.weight, %codon_decoder.transformer_decoder.layers.0.norm3.bias), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm3 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:2548:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_output_0 : Float(4, 30, strides=[30, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5053:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Cast_output_0 : Bool(4, 30, strides=[30, 1], device=cpu) = onnx::Cast[to=9, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Cast"](%/codon_decoder/Cast_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5054:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_1_output_0 : Float(device=cpu) = onnx::Constant[value={-inf}, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_1"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5054:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Where_output_0 : Float(4, 30, strides=[30, 1], requires_grad=0, device=cpu) = onnx::Where[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Where"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Cast_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_1_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5054:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Transpose_output_0 : Float(30, 4, 64, strides=[64, 1920, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Transpose"](%/codon_decoder/transformer_decoder/layers.0/norm3/LayerNormalization_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:1209:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/MatMul_output_0 : Float(30, 4, 192, strides=[768, 192, 1], device=cpu) = onnx::MatMul[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/MatMul"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Transpose_output_0, %onnx::MatMul_1302), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4810:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Add_output_0 : Float(30, 4, 192, strides=[768, 192, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Add"](%codon_decoder.transformer_decoder.layers.1.self_attn.in_proj_bias, %/codon_decoder/transformer_decoder/layers.1/self_attn/MatMul_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4810:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_2_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  3  64 [ CPULongType{2} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_2"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_3"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_4"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Mod_output_0 : Long(1, strides=[1], device=cpu) = onnx::Mod[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Mod"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_3_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_4_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Shape"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Add_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_5"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_6"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_output_0 : Long(1, strides=[1], device=cpu) = onnx::Reshape[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Mod_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_6_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Slice_output_0 : Long(*, device=cpu) = onnx::Slice[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Slice"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Shape_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_5_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_7"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Add_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Add[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Add_1"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Mod_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_7_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_8"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Reshape[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_1"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Add_1_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_8_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_9"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Slice_1_output_0 : Long(*, device=cpu) = onnx::Slice[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Slice_1"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Shape_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_1_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_9_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Concat_output_0 : Long(*, device=cpu) = onnx::Concat[axis=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Concat"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Slice_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_2_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Slice_1_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_2_output_0 : Float(30, 4, 3, 64, strides=[768, 192, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_2"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Add_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Concat_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_10"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4812:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Unsqueeze_output_0 : Float(1, 30, 4, 3, 64, strides=[23040, 768, 192, 64, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Unsqueeze"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_2_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_10_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4812:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Transpose_1_output_0 : Float(3, 30, 4, 1, 64, strides=[64, 768, 192, 23040, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[3, 1, 2, 0, 4], onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Transpose_1"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Unsqueeze_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4812:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_11"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4812:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Squeeze_output_0 : Float(3, 30, 4, 64, strides=[7680, 256, 64, 1], requires_grad=1, device=cpu) = onnx::Squeeze[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Squeeze"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Transpose_1_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_11_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4812:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Gather_output_0 : Float(30, 4, 64, strides=[256, 64, 1], requires_grad=1, device=cpu) = onnx::Gather[axis=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Gather"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Squeeze_output_0, %/Constant_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4813:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Gather_1_output_0 : Float(30, 4, 64, strides=[256, 64, 1], requires_grad=1, device=cpu) = onnx::Gather[axis=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Gather_1"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Squeeze_output_0, %/prot_encoder/pos_encoder/Constant_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4813:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Gather_2_output_0 : Float(30, 4, 64, strides=[256, 64, 1], requires_grad=1, device=cpu) = onnx::Gather[axis=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Gather_2"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Squeeze_output_0, %/prot_encoder/pos_encoder/Constant_1_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4813:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_12_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 30  16  16 [ CPULongType{3} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_12"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5315:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_3_output_0 : Float(30, 16, 16, strides=[256, 16, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_3"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Gather_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_12_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5315:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Transpose_2_output_0 : Float(16, 30, 16, strides=[16, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Transpose_2"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_3_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5315:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_13_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 30  16  16 [ CPULongType{3} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_13"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5317:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_4_output_0 : Float(30, 16, 16, strides=[256, 16, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_4"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Gather_1_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_13_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5317:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Transpose_3_output_0 : Float(16, 30, 16, strides=[16, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Transpose_3"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_4_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5317:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_14_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 30  16  16 [ CPULongType{3} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_14"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5326:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_5_output_0 : Float(30, 16, 16, strides=[256, 16, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_5"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Gather_2_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_14_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5326:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Transpose_4_output_0 : Float(16, 30, 16, strides=[16, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Transpose_4"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_5_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5326:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_15_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  4   1   1  30 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_15"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5352:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_6_output_0 : Float(4, 1, 1, 30, strides=[30, 30, 30, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_6"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Where_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_15_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5352:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_16_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value=-1  4 -1 -1 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_16"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_17"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/ConstantOfShape_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/ConstantOfShape"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_17_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_18"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Mul_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Mul"](%/codon_decoder/transformer_decoder/layers.1/self_attn/ConstantOfShape_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_18_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_19_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=-1  4 -1 -1 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_19"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Equal_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Equal"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_19_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Mul_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Where_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Where_1"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Equal_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/ConstantOfShape_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_16_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Expand_output_0 : Float(4, 4, 1, 30, strides=[30, 0, 30, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Expand"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_6_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Where_1_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_20_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 16   1  30 [ CPULongType{3} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_20"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_7_output_0 : Float(16, 1, 30, strides=[30, 30, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_7"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Expand_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_20_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Add_2_output_0 : Float(16, 30, 30, strides=[900, 30, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Add_2"](%/codon_decoder/transformer_decoder/layers.0/self_attn/Unsqueeze_1_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_7_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5357:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_21_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  4   4  -1  30 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_21"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5405:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_8_output_0 : Float(4, 4, 30, 30, strides=[3600, 900, 30, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_8"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Add_2_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_21_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5405:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_22_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  4   4  30  16 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_22"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5407:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_9_output_0 : Float(4, 4, 30, 16, strides=[64, 16, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_9"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Transpose_2_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_22_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5407:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_23_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  4   4  30  16 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_23"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5408:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_24_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  4   4  30  16 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_24"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5409:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_10_output_0 : Float(4, 4, 30, 16, strides=[64, 16, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_10"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Transpose_3_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_23_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5408:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_11_output_0 : Float(4, 4, 30, 16, strides=[64, 16, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_11"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Transpose_4_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_24_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5409:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Shape_1"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_9_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_25"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_26"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Slice_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Slice[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Slice_2"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Shape_1_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_25_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_26_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Cast_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Cast_1"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Slice_2_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Sqrt_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Sqrt"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Cast_1_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_27_output_0 : Float(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_27"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Div_output_0 : Float(1, strides=[1], device=cpu) = onnx::Div[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Div"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_27_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Sqrt_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Transpose_5_output_0 : Float(4, 4, 16, 30, strides=[1920, 480, 30, 1], device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Transpose_5"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_10_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Sqrt_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Sqrt_1"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Div_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Mul_1_output_0 : Float(4, 4, 30, 16, strides=[1920, 480, 16, 1], device=cpu) = onnx::Mul[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Mul_1"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_9_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Sqrt_1_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Sqrt_2_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Sqrt_2"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Div_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Mul_2_output_0 : Float(4, 4, 16, 30, strides=[1920, 480, 30, 1], device=cpu) = onnx::Mul[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Mul_2"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Transpose_5_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Sqrt_2_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/MatMul_1_output_0 : Float(4, 4, 30, 30, strides=[3600, 900, 30, 1], device=cpu) = onnx::MatMul[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/MatMul_1"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Mul_1_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Mul_2_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Add_3_output_0 : Float(4, 4, 30, 30, strides=[3600, 900, 30, 1], device=cpu) = onnx::Add[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Add_3"](%/codon_decoder/transformer_decoder/layers.1/self_attn/MatMul_1_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_8_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Softmax_output_0 : Float(4, 4, 30, 30, strides=[3600, 900, 30, 1], device=cpu) = onnx::Softmax[axis=-1, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Softmax"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Add_3_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/MatMul_2_output_0 : Float(4, 4, 30, 16, strides=[1920, 480, 16, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/MatMul_2"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Softmax_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_11_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Transpose_6_output_0 : Float(30, 4, 4, 16, strides=[256, 64, 16, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[2, 0, 1, 3], onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Transpose_6"](%/codon_decoder/transformer_decoder/layers.1/self_attn/MatMul_2_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5412:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_28_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 120   64 [ CPULongType{2} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_28"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5412:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_12_output_0 : Float(120, 64, strides=[64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_12"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Transpose_6_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_28_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5412:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Gemm_output_0 : Float(120, 64, strides=[64, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Gemm"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_12_output_0, %codon_decoder.transformer_decoder.layers.1.self_attn.out_proj.weight, %codon_decoder.transformer_decoder.layers.1.self_attn.out_proj.bias), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5414:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_29_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 30   4  64 [ CPULongType{3} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_29"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5415:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_13_output_0 : Float(30, 4, 64, strides=[256, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_13"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Gemm_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Constant_29_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5415:0
  %/codon_decoder/transformer_decoder/layers.1/self_attn/Transpose_7_output_0 : Float(4, 30, 64, strides=[64, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/codon_decoder/transformer_decoder/layers.1/self_attn/Transpose_7"](%/codon_decoder/transformer_decoder/layers.1/self_attn/Reshape_13_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:1243:0
  %/codon_decoder/transformer_decoder/layers.1/Add_output_0 : Float(4, 30, 64, strides=[1920, 64, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name="/codon_decoder/transformer_decoder/layers.1/Add"](%/codon_decoder/transformer_decoder/layers.0/norm3/LayerNormalization_output_0, %/codon_decoder/transformer_decoder/layers.1/self_attn/Transpose_7_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:755:0
  %/codon_decoder/transformer_decoder/layers.1/norm1/LayerNormalization_output_0 : Float(4, 30, 64, strides=[1920, 64, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/codon_decoder/transformer_decoder/layers.1/norm1/LayerNormalization"](%/codon_decoder/transformer_decoder/layers.1/Add_output_0, %codon_decoder.transformer_decoder.layers.1.norm1.weight, %codon_decoder.transformer_decoder.layers.1.norm1.bias), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm1 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:2548:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_output_0 : Float(4, 30, strides=[30, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5053:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Cast_output_0 : Bool(4, 30, strides=[30, 1], device=cpu) = onnx::Cast[to=9, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Cast"](%/prot_encoder/Cast_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5054:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_1_output_0 : Float(device=cpu) = onnx::Constant[value={-inf}, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_1"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5054:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Where_output_0 : Float(4, 30, strides=[30, 1], requires_grad=0, device=cpu) = onnx::Where[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Where"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Cast_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_1_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5054:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Transpose_output_0 : Float(30, 4, 64, strides=[64, 1920, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Transpose"](%/codon_decoder/transformer_decoder/layers.1/norm1/LayerNormalization_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:1211:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/MatMul_output_0 : Float(30, 4, 64, strides=[256, 64, 1], device=cpu) = onnx::MatMul[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/MatMul"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Transpose_output_0, %onnx::MatMul_1368), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4821:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Add_output_0 : Float(30, 4, 64, strides=[256, 64, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Add"](%onnx::Add_1365, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/MatMul_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4821:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/MatMul_1_output_0 : Float(30, 4, 128, strides=[512, 128, 1], device=cpu) = onnx::MatMul[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/MatMul_1"](%/codon_decoder/transformer_decoder/layers.0/multihead_attn/Transpose_1_output_0, %onnx::MatMul_1369), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4822:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Add_1_output_0 : Float(30, 4, 128, strides=[512, 128, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Add_1"](%onnx::Add_1367, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/MatMul_1_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4822:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_2_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  2  64 [ CPULongType{2} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_2"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_3"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_4"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Mod_output_0 : Long(1, strides=[1], device=cpu) = onnx::Mod[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Mod"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_3_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_4_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Shape"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Add_1_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_5"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_6"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_output_0 : Long(1, strides=[1], device=cpu) = onnx::Reshape[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Mod_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_6_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Slice_output_0 : Long(*, device=cpu) = onnx::Slice[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Slice"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Shape_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_5_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_7"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Add_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Add[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Add_2"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Mod_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_7_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_8"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Reshape[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_1"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Add_2_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_8_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_9"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Slice_1_output_0 : Long(*, device=cpu) = onnx::Slice[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Slice_1"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Shape_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_1_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_9_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Concat_output_0 : Long(*, device=cpu) = onnx::Concat[axis=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Concat"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Slice_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_2_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Slice_1_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_2_output_0 : Float(30, 4, 2, 64, strides=[512, 128, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_2"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Add_1_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Concat_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/_tensor.py:1192:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_10"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4824:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Unsqueeze_output_0 : Float(1, 30, 4, 2, 64, strides=[15360, 512, 128, 64, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Unsqueeze"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_2_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_10_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4824:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Transpose_1_output_0 : Float(2, 30, 4, 1, 64, strides=[64, 512, 128, 15360, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[3, 1, 2, 0, 4], onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Transpose_1"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Unsqueeze_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4824:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={3}, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_11"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4824:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Squeeze_output_0 : Float(2, 30, 4, 64, strides=[7680, 256, 64, 1], requires_grad=1, device=cpu) = onnx::Squeeze[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Squeeze"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Transpose_1_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_11_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4824:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Gather_output_0 : Float(30, 4, 64, strides=[256, 64, 1], requires_grad=1, device=cpu) = onnx::Gather[axis=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Gather"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Squeeze_output_0, %/Constant_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4825:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Gather_1_output_0 : Float(30, 4, 64, strides=[256, 64, 1], requires_grad=1, device=cpu) = onnx::Gather[axis=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Gather_1"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Squeeze_output_0, %/prot_encoder/pos_encoder/Constant_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:4825:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_12_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 30  16  16 [ CPULongType{3} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_12"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5315:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_3_output_0 : Float(30, 16, 16, strides=[256, 16, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_3"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Add_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_12_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5315:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Transpose_2_output_0 : Float(16, 30, 16, strides=[16, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Transpose_2"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_3_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5315:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_13_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 30  16  16 [ CPULongType{3} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_13"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5317:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_4_output_0 : Float(30, 16, 16, strides=[256, 16, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_4"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Gather_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_13_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5317:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Transpose_3_output_0 : Float(16, 30, 16, strides=[16, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Transpose_3"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_4_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5317:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_14_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 30  16  16 [ CPULongType{3} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_14"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5326:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_5_output_0 : Float(30, 16, 16, strides=[256, 16, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_5"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Gather_1_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_14_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5326:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Transpose_4_output_0 : Float(16, 30, 16, strides=[16, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Transpose_4"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_5_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5326:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_15_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  4   1   1  30 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_15"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5352:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_6_output_0 : Float(4, 1, 1, 30, strides=[30, 30, 30, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_6"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Where_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_15_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5352:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_16_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value=-1  4 -1 -1 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_16"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_17"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/ConstantOfShape_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/ConstantOfShape"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_17_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_18_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_18"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Mul_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Mul"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/ConstantOfShape_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_18_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_19_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=-1  4 -1 -1 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_19"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Equal_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Equal"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_19_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Mul_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Where_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Where_1"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Equal_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/ConstantOfShape_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_16_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Expand_output_0 : Float(4, 4, 1, 30, strides=[30, 0, 30, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Expand"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_6_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Where_1_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_20_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 16   1  30 [ CPULongType{3} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_20"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_7_output_0 : Float(16, 1, 30, strides=[30, 30, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_7"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Expand_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_20_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5353:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_21_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  4   4  -1  30 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_21"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5405:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_8_output_0 : Float(4, 4, 1, 30, strides=[120, 30, 30, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_8"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_7_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_21_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5405:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_22_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  4   4  30  16 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_22"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5407:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_9_output_0 : Float(4, 4, 30, 16, strides=[64, 16, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_9"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Transpose_2_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_22_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5407:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_23_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  4   4  30  16 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_23"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5408:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_24_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  4   4  30  16 [ CPULongType{4} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_24"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5409:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_10_output_0 : Float(4, 4, 30, 16, strides=[64, 16, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_10"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Transpose_3_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_23_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5408:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_11_output_0 : Float(4, 4, 30, 16, strides=[64, 16, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_11"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Transpose_4_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_24_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5409:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Shape_1"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_9_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_25"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_26"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Slice_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Slice[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Slice_2"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Shape_1_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_25_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_26_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Cast_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Cast[to=1, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Cast_1"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Slice_2_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Sqrt_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Sqrt"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Cast_1_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_27_output_0 : Float(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_27"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Div_output_0 : Float(1, strides=[1], device=cpu) = onnx::Div[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Div"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_27_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Sqrt_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Transpose_5_output_0 : Float(4, 4, 16, 30, strides=[1920, 480, 30, 1], device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Transpose_5"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_10_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Sqrt_1_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Sqrt_1"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Div_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Mul_1_output_0 : Float(4, 4, 30, 16, strides=[1920, 480, 16, 1], device=cpu) = onnx::Mul[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Mul_1"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_9_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Sqrt_1_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Sqrt_2_output_0 : Float(1, strides=[1], device=cpu) = onnx::Sqrt[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Sqrt_2"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Div_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Mul_2_output_0 : Float(4, 4, 16, 30, strides=[1920, 480, 30, 1], device=cpu) = onnx::Mul[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Mul_2"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Transpose_5_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Sqrt_2_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/MatMul_2_output_0 : Float(4, 4, 30, 30, strides=[3600, 900, 30, 1], device=cpu) = onnx::MatMul[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/MatMul_2"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Mul_1_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Mul_2_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Add_3_output_0 : Float(4, 4, 30, 30, strides=[3600, 900, 30, 1], device=cpu) = onnx::Add[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Add_3"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/MatMul_2_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_8_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Softmax_output_0 : Float(4, 4, 30, 30, strides=[3600, 900, 30, 1], device=cpu) = onnx::Softmax[axis=-1, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Softmax"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Add_3_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/MatMul_3_output_0 : Float(4, 4, 30, 16, strides=[1920, 480, 16, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/MatMul_3"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Softmax_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_11_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5411:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Transpose_6_output_0 : Float(30, 4, 4, 16, strides=[256, 64, 16, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[2, 0, 1, 3], onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Transpose_6"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/MatMul_3_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5412:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_28_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 120   64 [ CPULongType{2} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_28"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5412:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_12_output_0 : Float(120, 64, strides=[64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_12"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Transpose_6_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_28_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5412:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Gemm_output_0 : Float(120, 64, strides=[64, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Gemm"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_12_output_0, %codon_decoder.transformer_decoder.layers.1.multihead_attn.out_proj.weight, %codon_decoder.transformer_decoder.layers.1.multihead_attn.out_proj.bias), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5414:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_29_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 30   4  64 [ CPULongType{3} ], onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_29"](), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5415:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_13_output_0 : Float(30, 4, 64, strides=[256, 64, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_13"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Gemm_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Constant_29_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:5415:0
  %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Transpose_7_output_0 : Float(4, 30, 64, strides=[64, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name="/codon_decoder/transformer_decoder/layers.1/multihead_attn/Transpose_7"](%/codon_decoder/transformer_decoder/layers.1/multihead_attn/Reshape_13_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::multihead_attn # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:1243:0
  %/codon_decoder/transformer_decoder/layers.1/Add_1_output_0 : Float(4, 30, 64, strides=[1920, 64, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name="/codon_decoder/transformer_decoder/layers.1/Add_1"](%/codon_decoder/transformer_decoder/layers.1/norm1/LayerNormalization_output_0, %/codon_decoder/transformer_decoder/layers.1/multihead_attn/Transpose_7_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:756:0
  %/codon_decoder/transformer_decoder/layers.1/norm2/LayerNormalization_output_0 : Float(4, 30, 64, strides=[1920, 64, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/codon_decoder/transformer_decoder/layers.1/norm2/LayerNormalization"](%/codon_decoder/transformer_decoder/layers.1/Add_1_output_0, %codon_decoder.transformer_decoder.layers.1.norm2.weight, %codon_decoder.transformer_decoder.layers.1.norm2.bias), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm2 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:2548:0
  %/codon_decoder/transformer_decoder/layers.1/linear1/MatMul_output_0 : Float(4, 30, 256, strides=[7680, 256, 1], device=cpu) = onnx::MatMul[onnx_name="/codon_decoder/transformer_decoder/layers.1/linear1/MatMul"](%/codon_decoder/transformer_decoder/layers.1/norm2/LayerNormalization_output_0, %onnx::MatMul_1423), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.linear.Linear::linear1 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0
  %/codon_decoder/transformer_decoder/layers.1/linear1/Add_output_0 : Float(4, 30, 256, strides=[7680, 256, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name="/codon_decoder/transformer_decoder/layers.1/linear1/Add"](%codon_decoder.transformer_decoder.layers.1.linear1.bias, %/codon_decoder/transformer_decoder/layers.1/linear1/MatMul_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.linear.Linear::linear1 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0
  %/codon_decoder/transformer_decoder/layers.1/Relu_output_0 : Float(4, 30, 256, strides=[7680, 256, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name="/codon_decoder/transformer_decoder/layers.1/Relu"](%/codon_decoder/transformer_decoder/layers.1/linear1/Add_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:1475:0
  %/codon_decoder/transformer_decoder/layers.1/linear2/MatMul_output_0 : Float(4, 30, 64, strides=[1920, 64, 1], device=cpu) = onnx::MatMul[onnx_name="/codon_decoder/transformer_decoder/layers.1/linear2/MatMul"](%/codon_decoder/transformer_decoder/layers.1/Relu_output_0, %onnx::MatMul_1424), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.linear.Linear::linear2 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0
  %/codon_decoder/transformer_decoder/layers.1/linear2/Add_output_0 : Float(4, 30, 64, strides=[1920, 64, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name="/codon_decoder/transformer_decoder/layers.1/linear2/Add"](%codon_decoder.transformer_decoder.layers.1.linear2.bias, %/codon_decoder/transformer_decoder/layers.1/linear2/MatMul_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.linear.Linear::linear2 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0
  %/codon_decoder/transformer_decoder/layers.1/Add_2_output_0 : Float(4, 30, 64, strides=[1920, 64, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name="/codon_decoder/transformer_decoder/layers.1/Add_2"](%/codon_decoder/transformer_decoder/layers.1/norm2/LayerNormalization_output_0, %/codon_decoder/transformer_decoder/layers.1/linear2/Add_output_0), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:757:0
  %/codon_decoder/transformer_decoder/layers.1/norm3/LayerNormalization_output_0 : Float(4, 30, 64, strides=[1920, 64, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name="/codon_decoder/transformer_decoder/layers.1/norm3/LayerNormalization"](%/codon_decoder/transformer_decoder/layers.1/Add_2_output_0, %codon_decoder.transformer_decoder.layers.1.norm3.weight, %codon_decoder.transformer_decoder.layers.1.norm3.bias), scope: collage.model.Codon_Predictor::/collage.model.Codon_Decoder::codon_decoder/torch.nn.modules.transformer.TransformerDecoder::transformer_decoder/torch.nn.modules.transformer.TransformerDecoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm3 # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:2548:0
  %/linear/MatMul_output_0 : Float(4, 30, 65, strides=[1950, 65, 1], device=cpu) = onnx::MatMul[onnx_name="/linear/MatMul"](%/codon_decoder/transformer_decoder/layers.1/norm3/LayerNormalization_output_0, %onnx::MatMul_1425), scope: collage.model.Codon_Predictor::/torch.nn.modules.linear.Linear::linear # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0
  %/linear/Add_output_0 : Float(4, 30, 65, strides=[1950, 65, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name="/linear/Add"](%linear.bias, %/linear/MatMul_output_0), scope: collage.model.Codon_Predictor::/torch.nn.modules.linear.Linear::linear # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0
  %/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/Constant_4"](), scope: collage.model.Codon_Predictor:: # /home/auberon/programming/collage/collage/model.py:148:0
  %/Constant_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/Constant_5"](), scope: collage.model.Codon_Predictor:: # /home/auberon/programming/collage/collage/model.py:148:0
  %/Constant_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={30}, onnx_name="/Constant_6"](), scope: collage.model.Codon_Predictor:: # /home/auberon/programming/collage/collage/model.py:148:0
  %/Constant_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/Constant_7"](), scope: collage.model.Codon_Predictor:: # /home/auberon/programming/collage/collage/model.py:148:0
  %/Slice_output_0 : Double(4, 30, 65, strides=[1950, 65, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/Slice"](%/Where_output_0, %/Constant_5_output_0, %/Constant_6_output_0, %/Constant_4_output_0, %/Constant_7_output_0), scope: collage.model.Codon_Predictor:: # /home/auberon/programming/collage/collage/model.py:148:0
  %/Cast_output_0 : Double(4, 30, 65, strides=[1950, 65, 1], requires_grad=1, device=cpu) = onnx::Cast[to=11, onnx_name="/Cast"](%/linear/Add_output_0), scope: collage.model.Codon_Predictor:: # /home/auberon/programming/collage/collage/model.py:148:0
  %/Add_output_0 : Double(4, 30, 65, strides=[1950, 65, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name="/Add"](%/Cast_output_0, %/Slice_output_0), scope: collage.model.Codon_Predictor:: # /home/auberon/programming/collage/collage/model.py:148:0
  %output : Double(4, 30, 65, strides=[1950, 65, 1], requires_grad=1, device=cpu) = onnx::LogSoftmax[axis=-1, onnx_name="/softmax/LogSoftmax"](%/Add_output_0), scope: collage.model.Codon_Predictor::/torch.nn.modules.activation.LogSoftmax::softmax # /home/auberon/programming/collage/venv/lib/python3.10/site-packages/torch/nn/functional.py:1950:0
  return (%output)

======== Diagnostic Run torch.onnx.export version 2.1.0.dev20230514+cpu ========
verbose: False, log level: Level.ERROR
======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================

